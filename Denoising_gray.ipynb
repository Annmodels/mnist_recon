{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Denoising_gray.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSs2hc1Tcb11UsbjixQpaR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annmodels/mnist_recon/blob/master/Denoising_gray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QEmTdEQp7WU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from urllib import request\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG-oEtLXq-1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfkXgMAmrHb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOux-CI5sqXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf0D-mC2uBuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d zalando-research/fashionmnist "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EhpliQVvG9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "fn = \"fashionmnist.zip\"\n",
        "with ZipFile(fn,'r')as zip1:\n",
        "  zip1 = zip1.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1bdGWNxvoTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_database = np.loadtxt('fashion-mnist_train.csv',delimiter =',',skiprows = 1)[:,1:]\n",
        "print(img_database.shape)\n",
        "total_num_images = (img_database.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0yAHDJlwvvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784\n",
        "hidden1 = 620\n",
        "hidden2 = 448\n",
        "hidden3 = 224\n",
        "hidden4 = 112\n",
        "hidden5 = 56\n",
        "hidden6 = 28\n",
        "hidden7 = 28\n",
        "hidden8 = 56\n",
        "hidden9 = 112\n",
        "hidden8 = 224\n",
        "hidden9 = 448\n",
        "hidden10 = 620\n",
        "output_layer = 784"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2KKRIIoxxlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.05\n",
        "epochs = 30\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDJFUxioyAqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32,[None,n_input])\n",
        "y = tf.placeholder(tf.float32,[None,output_layer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BBniWlpzwoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\"w1\": tf.Variable(tf.random_normal([n_input,hidden1])),\n",
        "           \"w2\": tf.Variable(tf.random_normal([hidden1,hidden2])),\n",
        "           \"w3\": tf.Variable(tf.random_normal([hidden2,hidden3])),\n",
        "           \"w4\": tf.Variable(tf.random_normal([hidden3,hidden4])),\n",
        "           \"w5\": tf.Variable(tf.random_normal([hidden4,hidden5])),\n",
        "           \"w6\": tf.Variable(tf.random_normal([hidden5,hidden6])),\n",
        "           \"w7\": tf.Variable(tf.random_normal([hidden6,hidden7])),\n",
        "           \"w8\": tf.Variable(tf.random_normal([hidden7,hidden8])),\n",
        "           \"w9\": tf.Variable(tf.random_normal([hidden8,hidden9])),\n",
        "           \"w10\":tf.Variable(tf.random_normal([hidden9,hidden10])),\n",
        "           \"w11\": tf.Variable(tf.random_normal([hidden10,output_layer]))\n",
        "           }\n",
        "biases = {\"b1\":tf.Variable(tf.random.normal([hidden1])),\n",
        "          \"b2\":tf.Variable(tf.random.normal([hidden2])),\n",
        "          \"b3\":tf.Variable(tf.random.normal([hidden3])),\n",
        "          \"b4\":tf.Variable(tf.random.normal([hidden4])),\n",
        "          \"b5\":tf.Variable(tf.random.normal([hidden5])),\n",
        "          \"b6\":tf.Variable(tf.random.normal([hidden6])),\n",
        "          \"b7\":tf.Variable(tf.random.normal([hidden7])),\n",
        "          \"b8\":tf.Variable(tf.random.normal([hidden8])),\n",
        "          \"b9\":tf.Variable(tf.random.normal([hidden9])),\n",
        "          \"b10\":tf.Variable(tf.random.normal([hidden10])),\n",
        "          \"b11\":tf.Variable(tf.random.normal([output_layer]))\n",
        "          }\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ9i9Ajn6zX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z1 = tf.nn.sigmoid(tf.add(tf.matmul(x,weights[\"w1\"]),biases[\"b1\"]))\n",
        "z2 = tf.nn.sigmoid(tf.add(tf.matmul(z1,weights[\"w2\"]),biases[\"b2\"])) \n",
        "z3 = tf.nn.sigmoid(tf.add(tf.matmul(z2,weights[\"w3\"]),biases[\"b3\"]))\n",
        "z4 = tf.nn.sigmoid(tf.add(tf.matmul(z3,weights[\"w4\"]),biases[\"b4\"])) \n",
        "z5 = tf.nn.sigmoid(tf.add(tf.matmul(z4,weights[\"w5\"]),biases[\"b5\"])) \n",
        "z6 = tf.nn.sigmoid(tf.add(tf.matmul(z5,weights[\"w6\"]),biases[\"b6\"])) \n",
        "z7 = tf.nn.sigmoid(tf.add(tf.matmul(z6,weights[\"w7\"]),biases[\"b7\"])) \n",
        "z8 = tf.nn.sigmoid(tf.add(tf.matmul(z7,weights[\"w8\"]),biases[\"b8\"]))\n",
        "z9 = tf.nn.sigmoid(tf.add(tf.matmul(z8,weights[\"w9\"]),biases[\"b9\"]))\n",
        "z10 = tf.nn.sigmoid(tf.add(tf.matmul(z9,weights[\"w10\"]),biases[\"b10\"]))\n",
        "nn_output = tf.add(tf.matmul(z10,weights[\"w11\"]),biases[\"b11\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikf1ANXMylut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#z1 = tf.layers.dense(x,hidden1,activation = tf.nn.sigmoid)\n",
        "#3\": tf.Variable(tf.random_normal([hiddenhidden3])) = tf.layers.dense(z1,hidden2,activation = tf.nn.sigmoid)\n",
        "#3 = tf.layers.dense(z2,hidden3,activation = tf.nn.sigmoid)\n",
        "#1 = tf.nn.sigmoid(tf.add(tf.matmul(x,weights[\"w1\"]),biases[\"b1\"]))  = tf.layers.dense(z3,hidden4,activation = tf.nn.sigmoid)\n",
        "#5 = tf.layers.dense(z4,hidden5,activation = tf.nn.sigmoid)\n",
        "# = tf.nn.sigmoid(tf.add(tf.matmul(x,weights[\"w1\"]),biases[\"b1\"]))  = tf.layers.dense(z5,hidden6,activation = tf.nn.sigmoid)\n",
        "#7 = tf.layers.dense(z6,hidden7,activation = tf.nn.sigmoid)\n",
        "#1 = tf.nn.sigmoid(tf.add(tf.matmul(x,weights[\"w1\"]),biases[\"b1\"])) = tf.layers.dense(z7,hidden8,activation = tf.nn.sigmoid)\n",
        "#n_output = tf.layers.dense(z8,output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Ynglsj6yNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(img_database)\n",
        "x_train = img_database\n",
        "#normalize\n",
        "#x_train = x_train\n",
        "x_train_noisy = x_train + 10*np.random.normal(0,1,size = x_train.shape)\n",
        "plt.imshow(x_train[0].reshape(28,28),cmap = 'gray')\n",
        "plt.show()\n",
        "plt.imshow(x_train_noisy[0].reshape(28,28),cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8KKJeS-_f1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(nn_output)\n",
        "#print(y)\n",
        "closs = tf.reduce_mean(tf.square(nn_output-y))\n",
        "optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(closs)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgpyCN9QAQEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_actual = x_train[:10]\n",
        "noisy_image = x_train_noisy[:10]\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(int(total_num_images/batch_size)):\n",
        "      x_epoch = x_train[i*batch_size:(i+1)*batch_size]\n",
        "      x_noise_epoch = x_train_noisy[i*batch_size:(i+1)*batch_size]\n",
        "      _,loss = sess.run([optimizer,closs],feed_dict = {x:x_noise_epoch,y:x_epoch})\n",
        "    print(\"epoch\",epoch,'/',epochs,'loss:',loss)\n",
        "  denoised = sess.run(nn_output,feed_dict = {x:noisy_image})\n",
        "  #print(denoised.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA2YhFjkWX8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import zipfile \n",
        "fig,axes = plt.subplots(nrows = 3,ncols =10,sharex = True,sharey =True,figsize = (20,4))\n",
        "for images,row in zip([x_actual,noisy_image,denoised],axes):\n",
        "  for img,ax in zip(images,row):\n",
        "    ax.imshow(img.reshape((28,28)),cmap = 'gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "fig.tight_layout(pad = 0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}