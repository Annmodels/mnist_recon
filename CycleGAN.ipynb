{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyML8yQxWHFihxubFbGXA/+m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annmodels/mnist_recon/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG-W7hsvU092",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.ndimage.interpolation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qAYEc60UK1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1LN8GzXWrjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir MNIST_Fashion\n",
        "!mv *.gz MNIST_Fashion/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bonyblRXlSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_Fashion/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr-y2YaGYjyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (1,1))\n",
        "sample_image = mnist.train.next_batch(1)[0]\n",
        "sample_image = sample_image.reshape([28,28])\n",
        "plt.imshow(sample_image , cmap = \"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXAK768jeTZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrate = 0.0002\n",
        "batch_size = 40\n",
        "epochs = 124000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpDj-J-rewDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dim = 784\n",
        "gen_h1 = 128\n",
        "disc_h1 = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI6vmNH_fPTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier_init(shape):\n",
        "  return tf.random_normal(shape = shape , stddev = 1./tf.sqrt(shape[0]/2.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZOGtiQEf5WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wnb():\n",
        "  weights = {\n",
        "      \"disc_h1\": tf.Variable(xavier_init([image_dim , disc_h1])),\n",
        "      \"disc_final\": tf.Variable(xavier_init([disc_h1 , 1])),\n",
        "      \"gen_h1\": tf.Variable(xavier_init([image_dim , gen_h1])),\n",
        "      \"gen_final\": tf.Variable(xavier_init([gen_h1 , image_dim]))\n",
        "      }\n",
        "      \n",
        "  biases = {\n",
        "      \"disc_h1\": tf.Variable(xavier_init([disc_h1])),\n",
        "      \"disc_final\": tf.Variable(xavier_init([1])),\n",
        "      \"gen_h1\": tf.Variable(xavier_init([gen_h1])),\n",
        "      \"gen_final\": tf.Variable(xavier_init([image_dim]))\n",
        "      }\n",
        "  return weights,biases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pwW1nOdyMWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_a = tf.placeholder(tf.float32 , shape = [None , image_dim])\n",
        "x_b = tf.placeholder(tf.float32 , shape = [None , image_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqFQ5sicvAPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights,bias = wnb()\n",
        "def DiscriminatorAnB(x):\n",
        "  hidn_layer = tf.nn.relu(tf.add(tf.matmul(x , weights[\"disc_h1\"]) , bias[\"disc_h1\"]))\n",
        "  final_layer = tf.add(tf.matmul(hidn_layer , weights[\"disc_final\"]) , bias[\"disc_final\"])\n",
        "  disc_prob_output = tf.nn.sigmoid(final_layer)\n",
        "  return disc_prob_output\n",
        "\n",
        "def GeneratorABnBA(x):\n",
        "  hidn_layer = tf.nn.relu(tf.add(tf.matmul(x , weights[\"gen_h1\"]) , bias[\"gen_h1\"]))\n",
        "  final_layer = tf.add(tf.matmul(hidn_layer , weights[\"gen_final\"]) , bias[\"gen_final\"])\n",
        "  gen_prob_output = tf.nn.sigmoid(final_layer)\n",
        "  return gen_prob_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKo-KWM-3eAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#weights,bias = wnb()\n",
        "Generator_var = [weights[\"gen_h1\"],weights[\"gen_final\"],bias[\"gen_h1\"],bias[\"gen_final\"]]\n",
        "Discriminator_var = [weights[\"disc_h1\"],weights[\"disc_final\"],bias[\"disc_h1\"],bias[\"disc_final\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvscOCVBeDvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_ba = GeneratorABnBA(x_b)\n",
        "disc_a_real = DiscriminatorAnB(x_a)\n",
        "disc_a_fake = DiscriminatorAnB(x_ba)\n",
        "\n",
        "x_ab = GeneratorABnBA(x_a)\n",
        "disc_b_real = DiscriminatorAnB(x_b)\n",
        "disc_b_fake = DiscriminatorAnB(x_ab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_87NCLIHfvy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_disc_a = (tf.reduce_mean(tf.square(disc_a_real - tf.ones_like(disc_a_real))) + tf.reduce_mean(tf.square(disc_a_fake)))/2.0\n",
        "loss_disc_b = (tf.reduce_mean(tf.square(disc_b_real - tf.ones_like(disc_b_real))) + tf.reduce_mean(tf.square(disc_b_fake)))/2.0\n",
        "Discriminator_Loss = loss_disc_a + loss_disc_b\n",
        "\n",
        "x_bab = GeneratorABnBA(x_ba)\n",
        "x_aba = GeneratorABnBA(x_ab)\n",
        "\n",
        "loss_gen_a = tf.reduce_mean(tf.square(disc_a_fake - tf.ones_like(disc_a_fake)))\n",
        "loss_gen_b = tf.reduce_mean(tf.square(disc_b_fake - tf.ones_like(disc_b_fake)))\n",
        "loss_total = loss_gen_a + loss_gen_b\n",
        "\n",
        "loss_recon_a = tf.reduce_mean(10*tf.abs([x_a - x_aba]))\n",
        "loss_recon_b = tf.reduce_mean(10*tf.abs([x_b - x_bab]))\n",
        "loss_recon_total = loss_recon_a + loss_recon_b\n",
        "Generator_Loss = loss_total + loss_recon_total\n",
        "               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH3jmZwP6NDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"Optimizer_Discriminator\")as scope:\n",
        "  Discriminator_optimize = tf.train.AdamOptimizer(learning_rate = lrate).minimize(Discriminator_Loss , var_list = Discriminator_var)\n",
        "\n",
        "with tf.name_scope(\"Optimizer_Generator\")as scope:\n",
        "  Generator_optimize = tf.train.AdamOptimizer(learning_rate = lrate).minimize(Generator_Loss , var_list = Generator_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_RGXdu8m0z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = mnist.train.images\n",
        "mid = int(x_train.shape[0]/2)\n",
        "x_train_real = x_train[:mid]\n",
        "\n",
        "x_train_rotated = x_train[mid:].reshape(-1,28,28)\n",
        "x_train_rotated = scipy.ndimage.interpolation.rotate(x_train_rotated,90,axes = (1,2))\n",
        "x_train_rotated = x_train_rotated.reshape(-1,28*28)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUCEdk59pBrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_data(x,size):\n",
        "  start_index = np.random.randint(0,x.shape[0]-size)\n",
        "  return x[start_index:start_index+size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L2xcQgm8Cty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  x_a_batch = shuffle_data(x_train_real,batch_size)\n",
        "  x_b_batch = shuffle_data(x_train_rotated,batch_size)\n",
        "  _,Disc_loss_epoch = sess.run([Discriminator_optimize,Discriminator_Loss],feed_dict = {x_a:x_a_batch , x_b:x_b_batch}) \n",
        "  _,Gen_loss_epoch = sess.run([Generator_optimize,Generator_Loss],feed_dict = {x_a:x_a_batch , x_b:x_b_batch})\n",
        "  if epoch%2000 == 0:\n",
        "    print(\"steps: {0}  G_loss: {1} , D_loss: {2}\".format(epoch,Gen_loss_epoch,Disc_loss_epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBULlzhBGV3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 6\n",
        "canvas1 = np.empty((28*n,28*n))\n",
        "canvas2 = np.empty((28*n,28*n))\n",
        "for i in range(n):\n",
        "  test_a = shuffle_data(x_train_real,batch_size)\n",
        "  test_b = shuffle_data(x_train_rotated,batch_size)\n",
        "  out_a = sess.run(x_ba , feed_dict = {x_b:test_b})\n",
        "  out_b = sess.run(x_ab , feed_dict = {x_a:test_a})\n",
        "  #out_a = -1*(out_a-1)\n",
        "  #out_b = -1*(out_b-1)\n",
        "  for j in range(n):\n",
        "    canvas1[i*28:(i+1)*28 , j*28:(j+1)*28] = out_a[j].reshape([28,28])\n",
        "  for j in range(n):\n",
        "    canvas2[i*28:(i+1)*28 , j*28:(j+1)*28] = out_b[j].reshape([28,28])\n",
        "\n",
        "plt.figure(figsize = (n,n))\n",
        "plt.imshow(canvas1 , origin = \"upper\" , cmap = \"gray\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize = (n,n))\n",
        "plt.imshow(canvas2 , origin = \"upper\" , cmap = \"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}