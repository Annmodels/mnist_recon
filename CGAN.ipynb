{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOeelP8DNZhhxSpDv5xj0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annmodels/mnist_recon/blob/master/CGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG-W7hsvU092",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qAYEc60UK1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1LN8GzXWrjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir MNIST_Fashion\n",
        "!mv *.gz MNIST_Fashion/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bonyblRXlSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_Fashion/',one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr-y2YaGYjyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (1,1))\n",
        "sample_image,img_label = mnist.train.next_batch(1)\n",
        "print(img_label)\n",
        "sample_image = sample_image.reshape([28,28])\n",
        "plt.imshow(sample_image , cmap = \"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXAK768jeTZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrate = 0.0002\n",
        "batch_size = 100\n",
        "epochs = 50000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpDj-J-rewDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dim = 784\n",
        "y_dim = 10\n",
        "gen_hidn_dim = 400\n",
        "disc_hidn_dim = 400\n",
        "z_noise_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI6vmNH_fPTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier_init(shape):\n",
        "  return tf.random_normal(shape = shape , stddev = 1./tf.sqrt(shape[0]/2.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZOGtiQEf5WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\n",
        "    \"disc_h\": tf.Variable(xavier_init([image_dim+y_dim , disc_hidn_dim])),\n",
        "    \"disc_final\": tf.Variable(xavier_init([disc_hidn_dim , 1])),\n",
        "    \"gen_h\": tf.Variable(xavier_init([z_noise_dim+y_dim , gen_hidn_dim])),\n",
        "    \"gen_final\": tf.Variable(xavier_init([gen_hidn_dim , image_dim]))\n",
        "          }\n",
        "bias = {\n",
        "    \"disc_h\": tf.Variable(xavier_init([disc_hidn_dim])),\n",
        "    \"disc_final\": tf.Variable(xavier_init([1])),\n",
        "    \"gen_h\": tf.Variable(xavier_init([gen_hidn_dim])),\n",
        "    \"gen_final\": tf.Variable(xavier_init([image_dim]))\n",
        "       }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqFQ5sicvAPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator(x,y):\n",
        "  inputnl = tf.concat(axis = 1,values = (x,y))\n",
        "  hidn_layer = tf.nn.relu(tf.add(tf.matmul(inputnl , weights[\"disc_h\"]) , bias[\"disc_h\"]))\n",
        "  final_layer = tf.add(tf.matmul(hidn_layer , weights[\"disc_final\"]) , bias[\"disc_final\"])\n",
        "  disc_output = tf.nn.sigmoid(final_layer)\n",
        "  return final_layer,disc_output\n",
        "\n",
        "def Generator(x,y):\n",
        "  inputnl = tf.concat(axis = 1,values = (x,y))\n",
        "  hidn_layer = tf.nn.relu(tf.add(tf.matmul(inputnl , weights[\"gen_h\"]) , bias[\"gen_h\"]))\n",
        "  final_layer = tf.add(tf.matmul(hidn_layer , weights[\"gen_final\"]) , bias[\"gen_final\"])\n",
        "  gen_output = tf.nn.sigmoid(final_layer)\n",
        "  return gen_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pwW1nOdyMWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_input = tf.placeholder(tf.float32 , shape = [None , z_noise_dim] , name = \"input_noise\")\n",
        "x_input = tf.placeholder(tf.float32 , shape = [None , image_dim] , name = \"real_input\")\n",
        "y_input = tf.placeholder(tf.float32 , shape = [None , y_dim] , name = \"labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXhJIsbHzQ_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"Generator\")as scope:\n",
        "  output_gen = Generator(z_input,y_input)\n",
        "\n",
        "with tf.name_scope(\"Discriminator\")as scope:\n",
        "  real_output1_disc,real_output_disc = Discriminator(x_input,y_input)\n",
        "  fake_output1_disc,fake_output_disc = Discriminator(output_gen,y_input)\n",
        "\n",
        "with tf.name_scope(\"Discriminator_Loss\")as scope:\n",
        "  Discriminator_Loss = - tf.reduce_mean(tf.log(real_output_disc + 0.0001)+tf.log(1.-fake_output_disc + 0.0001))\n",
        "\n",
        "with tf.name_scope(\"Genetaror_loss\")as scope:\n",
        "  Generator_Loss = -tf.reduce_mean(tf.log(fake_output_disc + 0.0001)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKo-KWM-3eAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generator_var = [weights[\"gen_h\"],weights[\"gen_final\"],bias[\"gen_h\"],bias[\"gen_final\"]]\n",
        "Discriminator_var = [weights[\"disc_h\"],weights[\"disc_final\"],bias[\"disc_h\"],bias[\"disc_final\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH3jmZwP6NDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"Optimizer_Discriminator\")as scope:\n",
        "  Discriminator_optimize = tf.train.AdamOptimizer(learning_rate = lrate).minimize(Discriminator_Loss , var_list = Discriminator_var)\n",
        "\n",
        "with tf.name_scope(\"Optimizer_Generator\")as scope:\n",
        "  Generator_optimize = tf.train.AdamOptimizer(learning_rate = lrate).minimize(Generator_Loss , var_list = Generator_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L2xcQgm8Cty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  x_batch,y_label = mnist.train.next_batch(batch_size)\n",
        "  z_noise = np.random.uniform(-1.,1.,size = [batch_size , z_noise_dim]) \n",
        "  _,Disc_loss_epoch = sess.run([Discriminator_optimize,Discriminator_Loss],feed_dict = {x_input:x_batch,y_input:y_label,z_input:z_noise}) \n",
        "  _,Gen_loss_epoch = sess.run((Generator_optimize,Generator_Loss),feed_dict = {z_input:z_noise,y_input:y_label})\n",
        "  if epoch%2000 == 0:\n",
        "    print(\"steps: {0}  G_loss: {1} , D_loss: {2}\".format(epoch,Gen_loss_epoch,Disc_loss_epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clw0I5MeMPtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_plot(samples):\n",
        "  fig = plt.figure(figsize = (4,4))\n",
        "  gs = gridspec.GridSpec(4,4)\n",
        "  gs.update(wspace = 0.05,hspace = 0.05)\n",
        "  for i,sample in enumerate(samples):\n",
        "    ax = plt.subplot(gs[i])\n",
        "    plt.axis('off')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect('equal')\n",
        "    plt.imshow(sample.reshape(28,28),cmap = 'gray')\n",
        "  return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfvwbataOFYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create(input):\n",
        "  feature_map = {\n",
        "      \"tshirt\"     :0,\n",
        "      \"trouser\"    :1,\n",
        "      \"pullover\"   :2,\n",
        "      \"dress\"      :3,\n",
        "      \"coat\"       :4,\n",
        "      \"sandal\"     :5,\n",
        "      \"shorts\"     :6,\n",
        "      \"sneaker\"    :7,\n",
        "      \"bag\"        :8,\n",
        "      \"ankel_boot\" :9\n",
        "  }\n",
        "  samples = 16\n",
        "  z_noise = np.random.uniform(-1.,1.,size = [samples,z_noise_dim])\n",
        "  Y_label = np.zeros(shape = [samples,y_dim])\n",
        "  Y_label[:,feature_map[input]] = 1\n",
        " # print(Y_label)\n",
        "  generated_samples = sess.run(output_gen , feed_dict = {z_input:z_noise,y_input:Y_label})\n",
        "  generate_plot(generated_samples)\n",
        "  plt.savefig('{}.png'.format(str(\"test\").zfill(3)),bbox_inches = 'tight')\n",
        "\n",
        "create(\"coat\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}