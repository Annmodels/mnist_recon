{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmue57gwP1U+OWQjTG7Ywx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annmodels/mnist_recon/blob/master/AAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG-W7hsvU092",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qAYEc60UK1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1LN8GzXWrjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir MNIST_Fashion\n",
        "!mv *.gz MNIST_Fashion/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bonyblRXlSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_Fashion/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr-y2YaGYjyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (1,1))\n",
        "sample_image = mnist.train.next_batch(1)[0]\n",
        "sample_image = sample_image.reshape([28,28])\n",
        "plt.imshow(sample_image , cmap = \"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXAK768jeTZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrate = 0.0002\n",
        "batch_size = 32\n",
        "epochs = 50000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpDj-J-rewDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dim = 784\n",
        "nn_dim = 128\n",
        "latent_var_dim = 10\n",
        "z_noise_dim = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pwW1nOdyMWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_input = tf.placeholder(tf.float32 , shape = [None , z_noise_dim] , name = \"input_noise\")\n",
        "x_input = tf.placeholder(tf.float32 , shape = [None , image_dim] , name = \"real_input\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI6vmNH_fPTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier_init(shape):\n",
        "  return tf.random_normal(shape = shape , stddev = 1./tf.sqrt(shape[0]/2.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZOGtiQEf5WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc_wt = {\n",
        "    \"disc_hidn\": tf.Variable(xavier_init([latent_var_dim , nn_dim])),\n",
        "    \"disc_final\": tf.Variable(xavier_init([nn_dim , 1]))\n",
        "         }\n",
        "en_wt = {\n",
        "    \"en_1\": tf.Variable(xavier_init([image_dim , nn_dim])),\n",
        "    \"en_hidn\": tf.Variable(xavier_init([nn_dim , latent_var_dim]))\n",
        "        }\n",
        "d_wt = {\n",
        "    \"d_hidn\": tf.Variable(xavier_init([latent_var_dim , nn_dim])),\n",
        "    \"d_final\": tf.Variable(xavier_init([nn_dim , image_dim]))\n",
        "       }\n",
        "\n",
        "disc_bias = {\n",
        "    \"disc_hidn\": tf.Variable(xavier_init([nn_dim])),\n",
        "    \"disc_final\": tf.Variable(xavier_init([1]))\n",
        "            }\n",
        "en_bias = {\n",
        "    \"en_1\": tf.Variable(xavier_init([nn_dim])),\n",
        "    \"en_hidn\": tf.Variable(xavier_init([latent_var_dim]))\n",
        "          }\n",
        "d_bias = {\n",
        "        \"d_hidn\": tf.Variable(xavier_init([nn_dim])),\n",
        "        \"d_final\": tf.Variable(xavier_init([image_dim]))\n",
        "         }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqFQ5sicvAPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator(x):\n",
        "  hidn_layer = tf.nn.relu(tf.add(tf.matmul(x , disc_wt[\"disc_hidn\"]) , disc_bias[\"disc_hidn\"]))\n",
        "  final_layer = tf.add(tf.matmul(hidn_layer , disc_wt[\"disc_final\"]) , disc_bias[\"disc_final\"])\n",
        "  disc_output = tf.nn.sigmoid(final_layer)\n",
        "  return disc_output\n",
        "\n",
        "def Encoder(x):\n",
        "  hidn_layer = tf.nn.relu(tf.add(tf.matmul(x , en_wt[\"en_1\"]) , en_bias[\"en_1\"]))\n",
        "  en_output = tf.add(tf.matmul(hidn_layer , en_wt[\"en_hidn\"]) , en_bias[\"en_hidn\"])\n",
        "  return en_output\n",
        "\n",
        "def Decoder(x):\n",
        "  hidn_layer = tf.nn.relu(tf.add(tf.matmul(x , d_wt[\"d_hidn\"]) , d_bias[\"d_hidn\"]))\n",
        "  d_output = tf.add(tf.matmul(hidn_layer , d_wt[\"d_final\"]) , d_bias[\"d_final\"])\n",
        "  prob = tf.nn.sigmoid(d_output)\n",
        "  return prob,d_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d5S1NPVq0Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_output = Encoder(x_input)\n",
        "_,final_output = Decoder(latent_output)\n",
        "\n",
        "disc_real_output = Discriminator(z_input)\n",
        "disc_fake_output = Discriminator(latent_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeZzMyrCsD3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Discriminator_Loss = -tf.reduce_mean(tf.log(disc_real_output)+tf.log(1.0-disc_fake_output))\n",
        "Encoder_Loss = -tf.reduce_mean(tf.log(disc_fake_output))\n",
        "Decoder_Loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = final_output , labels = x_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKo-KWM-3eAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Discriminator_var = [disc_wt[\"disc_hidn\"],disc_wt[\"disc_final\"],disc_bias[\"disc_hidn\"],disc_bias[\"disc_final\"]]\n",
        "Encoder_var = [en_wt[\"en_1\"],en_wt[\"en_hidn\"],en_bias[\"en_1\"],en_bias[\"en_hidn\"]]\n",
        "Decoder_var = [d_wt[\"d_hidn\"],d_wt[\"d_final\"],d_bias[\"d_hidn\"],d_bias[\"d_final\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH3jmZwP6NDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Discriminator_optimize = tf.train.AdamOptimizer(learning_rate = lrate).minimize(Discriminator_Loss , var_list = Discriminator_var)\n",
        "Encoder_optimize = tf.train.AdamOptimizer(learning_rate = lrate).minimize(Encoder_Loss,var_list = Encoder_var)\n",
        "Decoder_optimize = tf.train.AdamOptimizer(learning_rate = lrate).minimize(Decoder_Loss , var_list = Encoder_var+Decoder_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L2xcQgm8Cty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  x_batch,_ = mnist.train.next_batch(batch_size)\n",
        "  z_noise = np.random.uniform(-1.,1.,size = [batch_size , z_noise_dim]) \n",
        "  _,D_loss_epoch = sess.run([Decoder_optimize,Decoder_Loss],feed_dict = {x_input:x_batch})\n",
        "  _,Disc_loss_epoch = sess.run([Discriminator_optimize,Discriminator_Loss],feed_dict = {x_input:x_batch,z_input:z_noise}) \n",
        "  _,En_loss_epoch = sess.run([Encoder_optimize,Encoder_Loss],feed_dict = {x_input:x_batch})\n",
        "  if epoch%2000 == 0:\n",
        "    print(\"steps: {0}  D_loss: {1} , En_loss: {2} , Disc_loss: {3}\".format(epoch,D_loss_epoch,En_loss_epoch,Disc_loss_epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBULlzhBGV3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_output,_ = Decoder(z_input)\n",
        "n = 6\n",
        "canvas = np.empty((28*n,28*n))\n",
        "for i in range(n):\n",
        "  z_noise = np.random.uniform(-1.,1.,size = [batch_size , z_noise_dim])\n",
        "  g = sess.run(test_output , feed_dict = {z_input:z_noise})\n",
        "  g = -1*(g-1)\n",
        "  for j in range(n):\n",
        "    canvas[i*28:(i+1)*28 , j*28:(j+1)*28] = g[j].reshape([28,28])\n",
        "\n",
        "plt.figure(figsize = (n,n))\n",
        "plt.imshow(canvas , origin = \"upper\" , cmap = \"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}